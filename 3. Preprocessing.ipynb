{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs preprocessing for all participants in the LDM experiment. Preprocessing consists of: \n",
    "* An epoching step which assigns gaze samples to trials \n",
    "* An alignment step which aligns gaze samples to AoIs and task cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Powered by NivLink0.2.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import scipy.io as io\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "from nivlink import Screen, Raw, Epochs, align_to_aoi, compute_fixations, plot_heatmaps\n",
    "import cv2\n",
    "import readline\n",
    "from math import dist\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "import warnings\n",
    "from scipy.stats import kde\n",
    "import nivlink\n",
    "import ipywidgets as wdg\n",
    "from scipy.stats import iqr\n",
    "print('Powered by NivLink' + str(nivlink.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. List participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 subjects.\n"
     ]
    }
   ],
   "source": [
    "all_subjects =  [23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 53, 54, \n",
    "                 55, 57, 58, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71];\n",
    "\n",
    "print('Found ' + str(len(all_subjects)) + ' subjects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper functions.\n",
    "\n",
    "To-do eventually: since these are used across multiple notebooks, add to a library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subj_data(subj_id):\n",
    "    \n",
    "    et_data_dir = os.getcwd().strip('ldm-analysis') + 'RawData/'# this expects RawData to be one directory up from the analysis repo\n",
    "    edf_path = et_data_dir + 'Sub' + str(subj_id) + 'ET.edf'\n",
    "    # Read subject's data from edf file.\n",
    "    data = Raw(edf_path)\n",
    "    # Filter out only eye position.\n",
    "    raw_pos_data = data.data[:,0,(0,1)]\n",
    "    # Grab messages for epoching step.\n",
    "    messages = data.messages \n",
    " \n",
    "    return data, raw_pos_data, messages, data.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_onsets(messages): \n",
    "    \"\"\" Returns run onsets. \n",
    "        \n",
    "        This function is specific to how the experiment code handles\n",
    "        messages to the EDF file during the task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    messages: array, shape (n_times, 1) \n",
    "        Array containing messages from the NivLink Raw object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    run_onsets : array, shape (n_runs, 2)\n",
    "        Run IDs and start indices.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n_messages = len(messages)\n",
    "    print('Found ' + str(n_messages) + ' messages...')\n",
    "    run_onsets = np.empty((0,3), dtype = int)\n",
    "\n",
    "    for m in np.arange(n_messages):\n",
    "        \n",
    "        this_message_index = messages[m][0]\n",
    "        this_message = messages[m][1]\n",
    "        \n",
    "        ## We encountered a new run.\n",
    "        if 'Run' in this_message:\n",
    "             \n",
    "            ## Get index of first XDAT 2 in this run. \n",
    "            ## This is specific to the LDM dataset\n",
    "            ## because the first stim onset is not align with the Start Run message.   \n",
    "            first_xdat2_message_index = messages[m+12][0]\n",
    "            first_xdat2_message = messages[m+12][1]\n",
    "            \n",
    "            ## Initialize onset array for this run.\n",
    "            this_run_onsets = np.empty((1,3), dtype = int); \n",
    "            \n",
    "            this_run_onsets[:,0] = int(this_message.strip('Run '))\n",
    "            # this_run_onsets[:,1] = int(this_message_index) # actual run start message\n",
    "            this_run_onsets[:,1] = int(first_xdat2_message_index)  # first XDAT2 in run\n",
    "              \n",
    "        ## Re-construct End Run message index by looking at the last trial in each run.\n",
    "        ## Assumes we consistently had 40 trial per run as per LDM_Run4.m\n",
    "        if 'Trial 40' in this_message:\n",
    "            \n",
    "            last_xdat1_message_index = messages[m+6][0]\n",
    "            last_xdat1_message = messages[m+6][1]\n",
    "            \n",
    "            this_run_onsets[:,2] = int(last_xdat1_message_index)\n",
    "            run_onsets = np.vstack((run_onsets,this_run_onsets))\n",
    "            \n",
    "    return run_onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rereference_events(subj_id, n_blocks, run_onsets, sfreq): \n",
    "    \"\"\"The events file is a `n_trials ` x 3 array which defines: \n",
    "    (1) the run/block number \n",
    "    (2) the trial onset relative to the first stimulus onset in the run (in seconds) \n",
    "    (3) the trial offset (in seconds) \n",
    "    Using the sample frequency, it gets re-referenced below to the NivLink 0.2 format: \n",
    "    (1) the event onset (in sample indices)\n",
    "    (2) start time before the event \n",
    "    (3) end time after the event \"\"\"\n",
    "\n",
    "    # Load file.\n",
    "    et_data_dir = os.getcwd().strip('ldm-analysis') + 'RawData/'# this expects RawData to be one directory up from the analysis repo\n",
    "    events_file_path = et_data_dir + str(subj_id) + 'events.mat'\n",
    "    events_mat = io.loadmat(events_file_path)\n",
    "    events = np.array(events_mat[\"events_array\"])\n",
    "    \n",
    "    # Record run onsets in events array. \n",
    "    new_col = events.sum(1)[...,None]*0\n",
    "    events = np.append(events, new_col, 1)\n",
    "    for b in np.arange(n_blocks):\n",
    "        block = b+1\n",
    "        this_block = events[:,0] == block\n",
    "        events[this_block,3] = run_onsets[block-1,1].astype(int) \n",
    "        \n",
    "    # Convert to dataframe.\n",
    "    events_df = pd.DataFrame(events)\n",
    "    events_df.columns = ['block','1', '2', '3']\n",
    "    \n",
    "    # Round events to sampling frequency.   \n",
    "    events_df['1'] = np.floor(events_df['1'] * sfreq) / sfreq\n",
    "    events_df['2'] = np.ceil(events_df['2'] * sfreq) / sfreq\n",
    "\n",
    "    # Re-reference events.\n",
    "    events_df['3'] += events_df['1'] * sfreq\n",
    "    events_df['2'] -= events_df['1']\n",
    "    events_df['1'] -= events_df['1']\n",
    "    \n",
    "    return events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Main pre-processing loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set data directory.\n",
    "et_data_dir = os.getcwd().strip('ldm-analysis') + 'RawData/'# this expects RawData to be one directory up from the analysis repo\n",
    "\n",
    "## Load all centers.\n",
    "all_centers = pd.read_csv(os.getcwd() + '/allCenters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing participant  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wg/m30l6kjs09l1pxs4fshqx1xxjyhc2c/T/ipykernel_90823/2886474336.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  centers['Block'] = [int(s.replace(sub + 'block' + '_', \"\")) for s in list(centers['Unnamed: 0'].values)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3493 messages...\n",
      "Block  1\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "40\n",
      "Block  2\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "80\n",
      "Block  3\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "120\n",
      "Block  4\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "160\n",
      "Block  5\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "200\n",
      "Block  6\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "240\n",
      "Block  7\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "280\n",
      "Block  8\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "320\n",
      "Block  9\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "360\n",
      "Block  10\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "400\n",
      "Percent of time spent looking outside valid AoIs: \n",
      "0.12001908192437057\n",
      "Preprocessing participant  26\n",
      "Found 3481 messages...\n",
      "Block  1\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "40\n",
      "Block  2\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "80\n",
      "Block  3\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "120\n",
      "Block  4\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "160\n",
      "Block  5\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "200\n",
      "Block  6\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "240\n",
      "Block  7\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "280\n",
      "Block  8\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "320\n",
      "Block  9\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "360\n",
      "Block  10\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "400\n",
      "Percent of time spent looking outside valid AoIs: \n",
      "0.07312521660312975\n",
      "Preprocessing participant  27\n",
      "Found 3611 messages...\n",
      "Block  1\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "40\n",
      "Block  2\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "80\n",
      "Block  3\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "120\n",
      "Block  4\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "160\n",
      "Block  5\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "200\n",
      "Block  6\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "240\n",
      "Block  7\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "280\n",
      "Block  8\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "320\n",
      "Block  9\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "360\n",
      "Block  10\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "400\n",
      "Percent of time spent looking outside valid AoIs: \n",
      "0.13973615343478354\n",
      "Preprocessing participant  28\n",
      "Found 3533 messages...\n",
      "Block  1\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "40\n",
      "Block  2\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "80\n",
      "Block  3\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "120\n",
      "Block  4\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "160\n",
      "Block  5\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "200\n",
      "Block  6\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "240\n",
      "Block  7\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "280\n",
      "Block  8\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "320\n",
      "Block  9\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "360\n",
      "Block  10\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "400\n",
      "Percent of time spent looking outside valid AoIs: \n",
      "0.1433907676481934\n",
      "Preprocessing participant  29\n",
      "Found 3462 messages...\n",
      "Block  1\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "40\n",
      "Block  2\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "80\n",
      "Block  3\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "120\n",
      "Block  4\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "160\n",
      "Block  5\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "200\n",
      "Block  6\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "240\n",
      "Block  7\n",
      "Adding AoIs... \n",
      "Epoching... \n",
      "Aligning to AoI...\n",
      "280\n",
      "Block  8\n",
      "Adding AoIs... \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wg/m30l6kjs09l1pxs4fshqx1xxjyhc2c/T/ipykernel_90823/2886474336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mcol_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'aoi'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aoi'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mthis_aoi_centers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_centers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_rectangle_aoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_aoi_centers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maoisidelength\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_aoi_centers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maoisidelength\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_aoi_centers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maoisidelength\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_aoi_centers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0maoisidelength\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m## Define null area as its own AoI.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EyetrackingProject/NivLink/nivlink/screen.py\u001b[0m in \u001b[0;36madd_rectangle_aoi\u001b[0;34m(self, xmin, xmax, ymin, ymax, screen_id)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mymin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mymax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscreen_id\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_aoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_ellipsoid_aoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_radius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_radius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/EyetrackingProject/NivLink/nivlink/screen.py\u001b[0m in \u001b[0;36m_update_aoi\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;34m\"\"\"Convenience function for updating AoI indices.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptional_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mergesort'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_index\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'quicksort'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Define screen metadata.\n",
    "xdim, ydim, n_screens = 1280, 1024, 1 \n",
    "aoisidelength = 162\n",
    "n_aois = 9\n",
    "\n",
    "## Initialize subject level containers.\n",
    "subj_all = []\n",
    "percent_null = []\n",
    "\n",
    "## Loop over participants and preprocess.\n",
    "for subj_id in all_subjects:\n",
    "    \n",
    "    if (subj_id == 58):\n",
    "        continue\n",
    "\n",
    "    print(\"Preprocessing participant \", subj_id)\n",
    "    subj_all.append(subj_id)\n",
    "\n",
    "    ## Set save path.\n",
    "    fixations_path = et_data_dir + str(subj_id) + 'fixations.csv'\n",
    "\n",
    "    ## Load data.\n",
    "    data, raw_pos_data, messages, sfreq = load_subj_data(subj_id)\n",
    "\n",
    "    ## Subset this participant's centers. \n",
    "    sub = 'Sub' + str(subj_id) + '_'\n",
    "    centers = all_centers[all_centers['Unnamed: 0'].str.contains(sub)]\n",
    "    centers['Block'] = [int(s.replace(sub + 'block' + '_', \"\")) for s in list(centers['Unnamed: 0'].values)]\n",
    "\n",
    "    ## Mark run onsets. \n",
    "    run_onsets = get_run_onsets(messages)\n",
    "    n_blocks, d = run_onsets.shape\n",
    "\n",
    "    ## Make block index indicator of same size as gaze data.\n",
    "    block_idx = np.zeros(len(raw_pos_data))\n",
    "    for r in np.arange(n_blocks):  \n",
    "        block_start = run_onsets[r,1]\n",
    "        block_end = run_onsets[r,2]    \n",
    "        block_idx[block_start-1:block_end-1] = r+1\n",
    "\n",
    "    ## Re-format events dataframe. \n",
    "    events_df = rereference_events(subj_id, n_blocks, run_onsets, sfreq)\n",
    "\n",
    "    ## Load feature map.\n",
    "    # The feature map file is a `n_trials` x `n_aoi` array which defines the cue corresponding to each AoI.\n",
    "    featmap_file_path = et_data_dir + str(subj_id) + 'featmap.mat'\n",
    "    featmap_mat = io.loadmat(featmap_file_path, struct_as_record=False, squeeze_me=True)\n",
    "    featmap = np.array(featmap_mat[\"features_aoi_map\"])\n",
    "\n",
    "    ## Initialize block level containers.\n",
    "    fixations = []\n",
    "    total_trials = 0\n",
    "    \n",
    "    ## Loop over blocks and preprocess.\n",
    "    for b in np.arange(n_blocks):\n",
    "\n",
    "        ## Retrieve block number. \n",
    "        block = b+1\n",
    "        print(\"Block \", block)\n",
    "\n",
    "        ## Initialize Screen object.\n",
    "        print(\"Adding AoIs... \")\n",
    "        info = Screen(xdim, ydim, n_screens)\n",
    "\n",
    "        ## Add AoIs.\n",
    "        # Grab block centers. \n",
    "        block_centers = centers[centers['Block'] == block]\n",
    "        # Add each AoI based on the custom center. \n",
    "        # 1-9 AoI numbering is consistent with left column -> middle column -> right column order.\n",
    "        for a in np.arange(n_aois):\n",
    "            col_names = ['aoi' + str(a) + '_x', 'aoi' + str(a) + '_y']\n",
    "            this_aoi_centers = block_centers[col_names].iloc[0].values\n",
    "            info.add_rectangle_aoi(this_aoi_centers[0]-aoisidelength//2, this_aoi_centers[0]+aoisidelength//2, this_aoi_centers[1]-aoisidelength//2, this_aoi_centers[1]+aoisidelength//2)\n",
    "\n",
    "        ## Define null area as its own AoI.\n",
    "        info.indices[info.indices == 0] = 10\n",
    "\n",
    "        ## Make epochs.\n",
    "        print(\"Epoching... \")\n",
    "        # Subselect this block's events.\n",
    "        this_block = events_df.loc[events_df['block'] == block]\n",
    "        this_block_idx = events_df.index[events_df['block'] == block].values \n",
    "        n_trials_block = this_block.shape[0]\n",
    "        # Make epochs without considering null AoI.\n",
    "        epochs = Epochs(data, this_block['3'].values, this_block['1'].values, this_block['2'].values, picks='gaze')\n",
    "\n",
    "        ## Align to AoI.\n",
    "        print(\"Aligning to AoI...\")\n",
    "        screen_idx_block = np.zeros((n_trials_block)).astype(int)\n",
    "        # Subselect featmap.\n",
    "        this_block_featmap = featmap[this_block_idx,:]\n",
    "        # Add \"null\" AoI.\n",
    "        this_block_featmap = np.hstack((this_block_featmap, np.ones((this_block_featmap.shape[0],1)) * 10))\n",
    "        n_trials_block = this_block.shape[0]\n",
    "        # Align. \n",
    "        aligned = align_to_aoi(epochs.data[:,:,0:2,:], info, screen_idx_block)\n",
    "\n",
    "        ## Compute fixations for this block. \n",
    "        fixations_block = compute_fixations(aligned[:,0,:], epochs.times)\n",
    "\n",
    "        ## Map fixations to task features.\n",
    "        fixations_block['Feature'] = this_block_featmap[fixations_block.Trial.values.astype(int)-1,fixations_block.AoI.values.astype(int)-1]      \n",
    "\n",
    "        ## Remove 0s fixations.\n",
    "        fixations_block = fixations_block[fixations_block['Duration'] != 0]\n",
    "        \n",
    "        ## Add trial indicator.\n",
    "        fixations_block['Trial'] = fixations_block['Trial'] + total_trials\n",
    "        total_trials = total_trials + n_trials_block \n",
    "\n",
    "        ## Append.\n",
    "        fixations.append(fixations_block)\n",
    "\n",
    "    ## Concatenate block df. \n",
    "    fixations = pd.concat(fixations)\n",
    "\n",
    "    ## Compute percentage of fixations outside AoI. \n",
    "    fixations_after_start = fixations[fixations['Onset'] > 0.2]\n",
    "    percent_null_subj = np.sum(fixations_after_start[fixations_after_start['AoI'] == 10]['Duration']) / np.sum(fixations_after_start['Duration'])\n",
    "    print('Percent of time spent looking outside valid AoIs: ')\n",
    "    print(percent_null_subj)\n",
    "    percent_null.append(percent_null_subj)\n",
    "\n",
    "    ## Save.\n",
    "    fixations.to_csv(fixations_path)\n",
    "\n",
    "## Save percentage of samples that fall outside AoI.\n",
    "dist_mean = pd.DataFrame({'subj': subj_all, \n",
    "               'percent_null': percent_null})\n",
    "dist_mean.to_csv('percent_null.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
