{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs preprocessing for all participants in the LDM experiment. Preprocessing consists of: \n",
    "* An epoching step which assigns gaze samples to trials \n",
    "* An alignment step which aligns gaze samples to AoIs and task cues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Powered by NivLink0.2.5\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib as matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import scipy.io as io\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "from nivlink import Screen, Raw, Epochs, align_to_aoi, compute_fixations, plot_heatmaps\n",
    "import cv2\n",
    "import readline\n",
    "from math import dist\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "import warnings\n",
    "from scipy.stats import kde\n",
    "import nivlink\n",
    "import ipywidgets as wdg\n",
    "from scipy.stats import iqr\n",
    "print('Powered by NivLink' + str(nivlink.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. List participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38 subjects.\n"
     ]
    }
   ],
   "source": [
    "all_subjects =  [23, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 53, 54, \n",
    "                 55, 57, 58, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71];\n",
    "\n",
    "print('Found ' + str(len(all_subjects)) + ' subjects.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper functions.\n",
    "\n",
    "To-do eventually: since these are used across multiple notebooks, add to a library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subj_data(subj_id):\n",
    "    \n",
    "    et_data_dir = os.getcwd().strip('ldm-analysis') + 'RawData/'# this expects RawData to be one directory up from the analysis repo\n",
    "    edf_path = et_data_dir + 'Sub' + str(subj_id) + 'ET.edf'\n",
    "    # Read subject's data from edf file.\n",
    "    data = Raw(edf_path)\n",
    "    # Filter out only eye position.\n",
    "    raw_pos_data = data.data[:,0,(0,1)]\n",
    "    # Grab messages for epoching step.\n",
    "    messages = data.messages \n",
    " \n",
    "    return data, raw_pos_data, messages, data.info['sfreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_onsets(messages): \n",
    "    \"\"\" Returns run onsets. \n",
    "        \n",
    "        This function is specific to how the experiment code handles\n",
    "        messages to the EDF file during the task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    messages: array, shape (n_times, 1) \n",
    "        Array containing messages from the NivLink Raw object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    run_onsets : array, shape (n_runs, 2)\n",
    "        Run IDs and start indices.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n_messages = len(messages)\n",
    "    print('Found ' + str(n_messages) + ' messages...')\n",
    "    run_onsets = np.empty((0,3), dtype = int)\n",
    "\n",
    "    for m in np.arange(n_messages):\n",
    "        \n",
    "        this_message_index = messages[m][0]\n",
    "        this_message = messages[m][1]\n",
    "        \n",
    "        ## We encountered a new run.\n",
    "        if 'Run' in this_message:\n",
    "             \n",
    "            ## Get index of first XDAT 2 in this run. \n",
    "            ## This is specific to the LDM dataset\n",
    "            ## because the first stim onset is not align with the Start Run message.   \n",
    "            first_xdat2_message_index = messages[m+12][0]\n",
    "            first_xdat2_message = messages[m+12][1]\n",
    "            \n",
    "            ## Initialize onset array for this run.\n",
    "            this_run_onsets = np.empty((1,3), dtype = int); \n",
    "            \n",
    "            this_run_onsets[:,0] = int(this_message.strip('Run '))\n",
    "            # this_run_onsets[:,1] = int(this_message_index) # actual run start message\n",
    "            this_run_onsets[:,1] = int(first_xdat2_message_index)  # first XDAT2 in run\n",
    "              \n",
    "        ## Re-construct End Run message index by looking at the last trial in each run.\n",
    "        ## Assumes we consistently had 40 trial per run as per LDM_Run4.m\n",
    "        if 'Trial 40' in this_message:\n",
    "            \n",
    "            last_xdat1_message_index = messages[m+6][0]\n",
    "            last_xdat1_message = messages[m+6][1]\n",
    "            \n",
    "            this_run_onsets[:,2] = int(last_xdat1_message_index)\n",
    "            run_onsets = np.vstack((run_onsets,this_run_onsets))\n",
    "            \n",
    "    return run_onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rereference_events(subj_id, n_blocks, run_onsets, sfreq): \n",
    "    \"\"\"The events file is a `n_trials ` x 3 array which defines: \n",
    "    (1) the run/block number \n",
    "    (2) the trial onset relative to the first stimulus onset in the run (in seconds) \n",
    "    (3) the trial offset (in seconds) \n",
    "    Using the sample frequency, it gets re-referenced below to the NivLink 0.2 format: \n",
    "    (1) the event onset (in sample indices)\n",
    "    (2) start time before the event \n",
    "    (3) end time after the event \"\"\"\n",
    "\n",
    "    # Load file.\n",
    "    et_data_dir = os.getcwd().strip('ldm-analysis') + 'RawData/'# this expects RawData to be one directory up from the analysis repo\n",
    "    events_file_path = et_data_dir + str(subj_id) + 'events.mat'\n",
    "    events_mat = io.loadmat(events_file_path)\n",
    "    events = np.array(events_mat[\"events_array\"])\n",
    "    \n",
    "    # Record run onsets in events array. \n",
    "    new_col = events.sum(1)[...,None]*0\n",
    "    events = np.append(events, new_col, 1)\n",
    "    for b in np.arange(n_blocks):\n",
    "        block = b+1\n",
    "        this_block = events[:,0] == block\n",
    "        events[this_block,3] = run_onsets[block-1,1].astype(int) \n",
    "        \n",
    "    # Convert to dataframe.\n",
    "    events_df = pd.DataFrame(events)\n",
    "    events_df.columns = ['block','1', '2', '3']\n",
    "    \n",
    "    # Round events to sampling frequency.   \n",
    "    events_df['1'] = np.floor(events_df['1'] * sfreq) / sfreq\n",
    "    events_df['2'] = np.ceil(events_df['2'] * sfreq) / sfreq\n",
    "\n",
    "    # Re-reference events.\n",
    "    events_df['3'] += events_df['1'] * sfreq\n",
    "    events_df['2'] -= events_df['1']\n",
    "    events_df['1'] -= events_df['1']\n",
    "    \n",
    "    return events_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Main pre-processing loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load all centers.\n",
    "all_centers = pd.read_csv(os.getcwd() + '/allCenters.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing this for one participant for now... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing participant  23\n",
      "Found 3493 messages...\n",
      "Block  1\n",
      "Adding AoIs... \n",
      "Epoching...  1\n",
      "Aligning to AoI...\n",
      "Block  2\n",
      "Adding AoIs... \n",
      "Epoching...  2\n",
      "Aligning to AoI...\n",
      "Block  3\n",
      "Adding AoIs... \n",
      "Epoching...  3\n",
      "Aligning to AoI...\n",
      "Block  4\n",
      "Adding AoIs... \n",
      "Epoching...  4\n",
      "Aligning to AoI...\n",
      "Block  5\n",
      "Adding AoIs... \n",
      "Epoching...  5\n",
      "Aligning to AoI...\n",
      "Block  6\n",
      "Adding AoIs... \n",
      "Epoching...  6\n",
      "Aligning to AoI...\n",
      "Block  7\n",
      "Adding AoIs... \n",
      "Epoching...  7\n",
      "Aligning to AoI...\n",
      "Block  8\n",
      "Adding AoIs... \n",
      "Epoching...  8\n",
      "Aligning to AoI...\n",
      "Block  9\n",
      "Adding AoIs... \n",
      "Epoching...  9\n",
      "Aligning to AoI...\n",
      "Block  10\n",
      "Adding AoIs... \n",
      "Epoching...  10\n",
      "Aligning to AoI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-132-d40d0a6d3325>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  centers['Block'] = [int(s.replace(sub + 'block' + '_', \"\")) for s in list(centers['Unnamed: 0'].values)]\n"
     ]
    }
   ],
   "source": [
    "## Set subject id.\n",
    "subj_id = all_subjects[0]\n",
    "print(\"Preprocessing participant \", subj_id)\n",
    "\n",
    "## Load data.\n",
    "data, raw_pos_data, messages, sfreq = load_subj_data(subj_id)\n",
    "\n",
    "## Subset this participant's centers. \n",
    "sub = 'Sub' + str(subj_id) + '_'\n",
    "centers = all_centers[all_centers['Unnamed: 0'].str.contains(sub)]\n",
    "centers['Block'] = [int(s.replace(sub + 'block' + '_', \"\")) for s in list(centers['Unnamed: 0'].values)]\n",
    "\n",
    "## Mark run onsets. \n",
    "run_onsets = get_run_onsets(messages)\n",
    "n_blocks, d = run_onsets.shape\n",
    "\n",
    "## Make block index indicator of same size as gaze data.\n",
    "block_idx = np.zeros(len(raw_pos_data))\n",
    "for r in np.arange(n_blocks):  \n",
    "    block_start = run_onsets[r,1]\n",
    "    block_end = run_onsets[r,2]    \n",
    "    block_idx[block_start-1:block_end-1] = r+1\n",
    "\n",
    "## Re-format events dataframe. \n",
    "events_df = rereference_events(subj_id, n_blocks, run_onsets, sfreq)\n",
    "\n",
    "## Load feature map.\n",
    "# The feature map file is a `n_trials` x `n_aoi` array which defines the cue corresponding to each AoI.\n",
    "et_data_dir = os.getcwd().strip('ldm-analysis') + 'RawData/'# this expects RawData to be one directory up from the analysis repo\n",
    "featmap_file_path = et_data_dir + str(subj_id) + 'featmap.mat'\n",
    "featmap_mat = io.loadmat(featmap_file_path, struct_as_record=False, squeeze_me=True)\n",
    "featmap = np.array(featmap_mat[\"features_aoi_map\"])\n",
    "\n",
    "## Loop over block and preprocess.\n",
    "fixations = []\n",
    "screen_idx = []\n",
    "total_trials = 0\n",
    "\n",
    "## Define screen metadata.\n",
    "xdim, ydim, n_screens = 1280, 1024, 1 \n",
    "\n",
    "for b in np.arange(n_blocks_total):\n",
    "\n",
    "    ## Retrieve block number. \n",
    "    block = b+1\n",
    "    print(\"Block \", block)\n",
    "    \n",
    "    ## Initialize Screen object.\n",
    "    print(\"Adding AoIs... \")\n",
    "    info = Screen(xdim, ydim, n_screens)\n",
    "\n",
    "    ## Add AoIs.\n",
    "    # Grab block centers. \n",
    "    block_centers = centers[centers['Block'] == block]\n",
    "    # Add each AoI based on the custom center. \n",
    "    for a in np.arange(n_aois):\n",
    "        col_names = ['aoi' + str(a) + '_x', 'aoi' + str(a) + '_y']\n",
    "        this_aoi_centers = block_centers[col_names].iloc[0].values\n",
    "        \n",
    "        ### \n",
    "        \n",
    "        # Change code below to add correct AoI based on info \n",
    "        # about centers and stim size. \n",
    "        # 1-9 AoI numbering is consistent with left column -> middle column -> right column order. \n",
    "    \n",
    "        # info.add_rectangle_aoi(xmin, xmax, ymin, ymax)\n",
    "        \n",
    "#         xmin, ymin : int or float\n",
    "#             Coordinates of top-left corner of AoI. Accepts absolute\n",
    "#             or fractional [0-1] position. \n",
    "#         xmax, ymax : int or float\n",
    "#           Coordinates of bottom-right corner of AoI.\n",
    "        \n",
    "        ### \n",
    "        \n",
    "    ## Make epochs.\n",
    "    print(\"Epoching... \", block)\n",
    "    # Subselect this block's events.\n",
    "    this_block = events_df.loc[events_df['block'] == block]\n",
    "    this_block_idx = events_df.index[events_df['block'] == block].values \n",
    "    n_trials_block = this_block.shape[0]\n",
    "    # Make epochs without considering null AoI.\n",
    "    epochs = Epochs(data, this_block['3'].values, this_block['1'].values, this_block['2'].values, picks='gaze')\n",
    "    \n",
    "    ## Align to AoI.\n",
    "    print(\"Aligning to AoI...\")\n",
    "    screen_idx_block = np.zeros((n_trials_block)).astype(int)\n",
    "    # Subselect featmap.\n",
    "    this_block_featmap = featmap[this_block_idx,:]\n",
    "    # Add \"null\" AoI.\n",
    "    this_block_featmap = np.hstack((this_block_featmap, np.ones((this_block_featmap.shape[0],1)) * 88))\n",
    "    n_trials_block = this_block.shape[0]\n",
    "    # Align. \n",
    "    aligned = align_to_aoi(epochs.data[:,:,0:2,:], info, screen_idx_block)\n",
    "\n",
    "    ## Compute fixations for this block. \n",
    "    fixations_block = compute_fixations(aligned[:,0,:], epochs.times)\n",
    "          \n",
    "        \n",
    "    ### \n",
    "    \n",
    "    # Stop here to check\n",
    "    \n",
    "    ### \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial</th>\n",
       "      <th>AoI</th>\n",
       "      <th>Onset</th>\n",
       "      <th>Offset</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Trial, AoI, Onset, Offset, Duration]\n",
       "Index: []"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixations_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
