{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook performs maximum likelihood estimation (MLE) for one participant's choices, under a feature reinforcement learning with decay model. The fitting procedure tests best fit (MLE) parameters on choice data from a left-out game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import dirichlet\n",
    "from scipy.optimize import minimize\n",
    "import time as time\n",
    "import pickle \n",
    "\n",
    "# Custom dependencies\n",
    "import os\n",
    "from World import World\n",
    "from FeatureRL import Agent as FRL\n",
    "from FeatureRL import train_frl_choice\n",
    "from Data import Data, extract_vars \n",
    "from fitting import Fit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiate world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set world properties.\n",
    "n_dims = 3\n",
    "n_feats_per_dim = 3\n",
    "world_h = 0\n",
    "world_p_high = 0.75\n",
    "world_p_low = 0.25\n",
    "outcome = 1\n",
    " \n",
    "world = World(n_dims, n_feats_per_dim, world_h, world_p_high, world_p_low, outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set paths.\n",
    "behav_path = os.getcwd() + '/subj1.csv'\n",
    "fit_path = os.getcwd() + '/subj1_MLE_fit.obj'\n",
    "fit_file = open(fit_path, 'wb')\n",
    "\n",
    "## Load csv. \n",
    "behav_data = pd.read_csv(behav_path)\n",
    "\n",
    "## Make data object.\n",
    "data = Data(behav_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run MLE with leave-one-game out cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration # 1\n",
      "initial conditions: [0.4135765898362317, 0.5567194749751273, 3.908749346233261]\n",
      "predicting game: 1\n",
      "total training set log likelihood: -213.978354575391\n",
      "total training set log likelihood: -213.97835665986793\n",
      "total training set log likelihood: -213.97835438795414\n",
      "total training set log likelihood: -213.97835455128836\n",
      "total training set log likelihood: -347.1577676865943\n",
      "total training set log likelihood: -347.15773053174274\n",
      "total training set log likelihood: -347.1577676865869\n",
      "total training set log likelihood: -347.1577676865885\n",
      "total training set log likelihood: -193.98246551583227\n",
      "total training set log likelihood: -193.98246533689903\n",
      "total training set log likelihood: -193.98246572480394\n",
      "total training set log likelihood: -193.98246545112974\n",
      "total training set log likelihood: -193.45415324888842\n",
      "total training set log likelihood: -193.4541531005889\n",
      "total training set log likelihood: -193.4541534596583\n",
      "total training set log likelihood: -193.4541531877297\n",
      "total training set log likelihood: -191.58676546654044\n",
      "total training set log likelihood: -191.58676543985015\n",
      "total training set log likelihood: -191.58676568350683\n",
      "total training set log likelihood: -191.58676541847623\n",
      "total training set log likelihood: -183.38062900914792\n",
      "total training set log likelihood: -183.38062922983033\n",
      "total training set log likelihood: -183.38062908686805\n",
      "total training set log likelihood: -183.38062899795872\n",
      "total training set log likelihood: -182.32978023311577\n",
      "total training set log likelihood: -182.3297801783347\n",
      "total training set log likelihood: -182.329780136402\n",
      "total training set log likelihood: -182.32978022656943\n",
      "total training set log likelihood: -182.07590900360032\n",
      "total training set log likelihood: -182.07590884593083\n",
      "total training set log likelihood: -182.07590902535262\n",
      "total training set log likelihood: -182.0759089977692\n",
      "total training set log likelihood: -182.00062095822926\n",
      "total training set log likelihood: -182.0006209923532\n",
      "total training set log likelihood: -182.0006209618127\n",
      "total training set log likelihood: -182.00062095650588\n",
      "total training set log likelihood: -181.9781896786787\n",
      "total training set log likelihood: -181.97818968955286\n",
      "total training set log likelihood: -181.97818967702858\n",
      "total training set log likelihood: -181.9781896777355\n",
      "total training set log likelihood: -181.97271915010012\n",
      "total training set log likelihood: -181.97271914927168\n",
      "total training set log likelihood: -181.97271914940404\n",
      "total training set log likelihood: -181.97271914999277\n",
      "total training set log likelihood: -181.97267077341624\n",
      "total training set log likelihood: -181.97267077330625\n",
      "total training set log likelihood: -181.97267077335457\n",
      "total training set log likelihood: -181.97267077341093\n",
      "total training set log likelihood: -181.9726705609677\n",
      "total training set log likelihood: -181.97267056096507\n",
      "total training set log likelihood: -181.9726705609666\n",
      "total training set log likelihood: -181.9726705609677\n",
      "maximum likelihood learning rate: 0.18098175182322057\n",
      "maximum likelihood decay rate: 0.417251524741565\n",
      "maximum likelihood beta on value: 8.053710108223282\n",
      "test set log likelihood: -15.585400988166915\n",
      "test set likelihood per trial: [0.44030647]\n",
      "predicting game: 2\n",
      "total training set log likelihood: -220.53249122950746\n",
      "total training set log likelihood: -220.5324933474404\n",
      "total training set log likelihood: -220.53249105382355\n",
      "total training set log likelihood: -220.5324912181911\n",
      "total training set log likelihood: -347.15878832096257\n",
      "total training set log likelihood: -347.1587613722622\n",
      "total training set log likelihood: -347.1587883209559\n",
      "total training set log likelihood: -347.1587883209572\n",
      "total training set log likelihood: -204.6115259303933\n",
      "total training set log likelihood: -204.61152567710107\n",
      "total training set log likelihood: -204.61152613879776\n",
      "total training set log likelihood: -204.61152584534597\n",
      "total training set log likelihood: -204.1427070184954\n",
      "total training set log likelihood: -204.1427069690173\n",
      "total training set log likelihood: -204.14270720581797\n",
      "total training set log likelihood: -204.1427069366665\n",
      "total training set log likelihood: -203.44633227005636\n",
      "total training set log likelihood: -203.44633241919465\n",
      "total training set log likelihood: -203.44633242139466\n",
      "total training set log likelihood: -203.44633219196805\n",
      "total training set log likelihood: -201.99034004399434\n",
      "total training set log likelihood: -201.9903404504215\n",
      "total training set log likelihood: -201.99034010736557\n",
      "total training set log likelihood: -201.99033997319697\n",
      "total training set log likelihood: -199.77254032515165\n",
      "total training set log likelihood: -199.77254086343302\n",
      "total training set log likelihood: -199.77254025276304\n",
      "total training set log likelihood: -199.77254026444217\n",
      "total training set log likelihood: -195.1875913395341\n",
      "total training set log likelihood: -195.18759167834995\n",
      "total training set log likelihood: -195.1875911736009\n",
      "total training set log likelihood: -195.1875912961153\n",
      "total training set log likelihood: -190.34363306019307\n",
      "total training set log likelihood: -190.34363267190892\n",
      "total training set log likelihood: -190.343633088483\n",
      "total training set log likelihood: -190.3436330377027\n",
      "total training set log likelihood: -189.6494535997621\n",
      "total training set log likelihood: -189.64945335022733\n",
      "total training set log likelihood: -189.6494536147525\n",
      "total training set log likelihood: -189.6494535870605\n",
      "total training set log likelihood: -189.2875286245363\n",
      "total training set log likelihood: -189.28752861469815\n",
      "total training set log likelihood: -189.28752862209095\n",
      "total training set log likelihood: -189.28752862284807\n",
      "total training set log likelihood: -189.27833182283126\n",
      "total training set log likelihood: -189.2783318263\n",
      "total training set log likelihood: -189.27833182280455\n",
      "total training set log likelihood: -189.2783318226409\n",
      "total training set log likelihood: -189.27802830927365\n",
      "total training set log likelihood: -189.27802830894427\n",
      "total training set log likelihood: -189.27802830907243\n",
      "total training set log likelihood: -189.2780283092647\n",
      "total training set log likelihood: -189.27802648745995\n",
      "total training set log likelihood: -189.27802648746706\n",
      "total training set log likelihood: -189.27802648746552\n",
      "total training set log likelihood: -189.27802648746024\n",
      "total training set log likelihood: -189.2780264861525\n",
      "total training set log likelihood: -189.2780264861525\n",
      "total training set log likelihood: -189.2780264861525\n",
      "total training set log likelihood: -189.27802648615256\n",
      "maximum likelihood learning rate: 0.17470786766879826\n",
      "maximum likelihood decay rate: 0.4012235270050728\n",
      "maximum likelihood beta on value: 7.857752240412865\n",
      "test set log likelihood: -8.154290491915024\n",
      "test set likelihood per trial: [0.65104717]\n",
      "predicting game: 3\n",
      "total training set log likelihood: -216.76661583552237\n",
      "total training set log likelihood: -216.76661791626796\n",
      "total training set log likelihood: -216.7666155949815\n",
      "total training set log likelihood: -216.76661581873836\n",
      "total training set log likelihood: -346.0597403000214\n",
      "total training set log likelihood: -346.05970899408464\n",
      "total training set log likelihood: -346.0597403000145\n",
      "total training set log likelihood: -346.0597403000159\n",
      "total training set log likelihood: -199.01475723095635\n",
      "total training set log likelihood: -199.0147569252226\n",
      "total training set log likelihood: -199.01475740532015\n",
      "total training set log likelihood: -199.01475715328812\n",
      "total training set log likelihood: -198.57472755616823\n",
      "total training set log likelihood: -198.57472741653146\n",
      "total training set log likelihood: -198.5747277180987\n",
      "total training set log likelihood: -198.5747274825582\n",
      "total training set log likelihood: -197.41230642693967\n",
      "total training set log likelihood: -197.41230661180077\n",
      "total training set log likelihood: -197.4123065644132\n",
      "total training set log likelihood: -197.41230636682496\n",
      "total training set log likelihood: -195.64007724283033\n",
      "total training set log likelihood: -195.64007773386763\n",
      "total training set log likelihood: -195.64007735581208\n",
      "total training set log likelihood: -195.64007720276052\n",
      "total training set log likelihood: -192.44651023694615\n",
      "total training set log likelihood: -192.44651091138726\n",
      "total training set log likelihood: -192.44651032794027\n",
      "total training set log likelihood: -192.44651022145675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training set log likelihood: -188.1545154311152\n",
      "total training set log likelihood: -188.1545159101216\n",
      "total training set log likelihood: -188.1545154211805\n",
      "total training set log likelihood: -188.15451543101784\n",
      "total training set log likelihood: -187.7123459053363\n",
      "total training set log likelihood: -187.7123456777581\n",
      "total training set log likelihood: -187.71234601799495\n",
      "total training set log likelihood: -187.7123459058658\n",
      "total training set log likelihood: -187.21976540231972\n",
      "total training set log likelihood: -187.21976544120452\n",
      "total training set log likelihood: -187.21976542100435\n",
      "total training set log likelihood: -187.219765404478\n",
      "total training set log likelihood: -187.20131119105667\n",
      "total training set log likelihood: -187.20131123393224\n",
      "total training set log likelihood: -187.20131119085121\n",
      "total training set log likelihood: -187.2013111928185\n",
      "total training set log likelihood: -187.1945882360195\n",
      "total training set log likelihood: -187.1945882480051\n",
      "total training set log likelihood: -187.19458823435818\n",
      "total training set log likelihood: -187.19458823681174\n",
      "total training set log likelihood: -187.19286555544954\n",
      "total training set log likelihood: -187.19286555494435\n",
      "total training set log likelihood: -187.19286555484155\n",
      "total training set log likelihood: -187.19286555552253\n",
      "total training set log likelihood: -187.19281325409267\n",
      "total training set log likelihood: -187.1928132538122\n",
      "total training set log likelihood: -187.19281325402963\n",
      "total training set log likelihood: -187.1928132540894\n",
      "total training set log likelihood: -187.19281271855726\n",
      "total training set log likelihood: -187.19281271855397\n",
      "total training set log likelihood: -187.19281271856133\n",
      "total training set log likelihood: -187.19281271855746\n",
      "total training set log likelihood: -187.19281271792494\n",
      "total training set log likelihood: -187.19281271792465\n",
      "total training set log likelihood: -187.19281271792502\n",
      "total training set log likelihood: -187.1928127179249\n",
      "maximum likelihood learning rate: 0.1839102134534498\n",
      "maximum likelihood decay rate: 0.4540902875955136\n",
      "maximum likelihood beta on value: 7.726659798216895\n",
      "test set log likelihood: -10.482864418162524\n",
      "test set likelihood per trial: [0.59206241]\n",
      "predicting game: 4\n",
      "total training set log likelihood: -210.76854789069694\n",
      "total training set log likelihood: -210.7685498365115\n",
      "total training set log likelihood: -210.76854780406757\n",
      "total training set log likelihood: -210.76854786945606\n",
      "total training set log likelihood: -346.059333720256\n",
      "total training set log likelihood: -346.0592983485924\n",
      "total training set log likelihood: -346.0593337202474\n",
      "total training set log likelihood: -346.05933372025015\n",
      "total training set log likelihood: -194.2933636170838\n",
      "total training set log likelihood: -194.29336350150152\n",
      "total training set log likelihood: -194.29336389439877\n",
      "total training set log likelihood: -194.29336355443155\n",
      "total training set log likelihood: -193.65333159765586\n",
      "total training set log likelihood: -193.6533315368945\n",
      "total training set log likelihood: -193.65333186190227\n",
      "total training set log likelihood: -193.65333153524818\n",
      "total training set log likelihood: -191.6117015007339\n",
      "total training set log likelihood: -191.611701687659\n",
      "total training set log likelihood: -191.61170169884065\n",
      "total training set log likelihood: -191.61170144048282\n",
      "total training set log likelihood: -187.62431769220072\n",
      "total training set log likelihood: -187.62431837864017\n",
      "total training set log likelihood: -187.62431745788714\n",
      "total training set log likelihood: -187.62431765070124\n",
      "total training set log likelihood: -183.36864176046623\n",
      "total training set log likelihood: -183.368641803693\n",
      "total training set log likelihood: -183.36864177728015\n",
      "total training set log likelihood: -183.3686417219687\n",
      "total training set log likelihood: -181.34145239761938\n",
      "total training set log likelihood: -181.34145185108991\n",
      "total training set log likelihood: -181.34145240759054\n",
      "total training set log likelihood: -181.34145236893406\n",
      "total training set log likelihood: -180.48093115535565\n",
      "total training set log likelihood: -180.48093080380193\n",
      "total training set log likelihood: -180.48093117656165\n",
      "total training set log likelihood: -180.48093113617185\n",
      "total training set log likelihood: -179.70846889173714\n",
      "total training set log likelihood: -179.7084688719682\n",
      "total training set log likelihood: -179.70846889408875\n",
      "total training set log likelihood: -179.70846888884202\n",
      "total training set log likelihood: -179.68223294878078\n",
      "total training set log likelihood: -179.68223295312688\n",
      "total training set log likelihood: -179.6822329481358\n",
      "total training set log likelihood: -179.6822329483146\n",
      "total training set log likelihood: -179.68094315805277\n",
      "total training set log likelihood: -179.6809431593108\n",
      "total training set log likelihood: -179.6809431580164\n",
      "total training set log likelihood: -179.6809431580435\n",
      "total training set log likelihood: -179.6809350063363\n",
      "total training set log likelihood: -179.68093500645102\n",
      "total training set log likelihood: -179.68093500632025\n",
      "total training set log likelihood: -179.6809350063383\n",
      "total training set log likelihood: -179.68093497811802\n",
      "total training set log likelihood: -179.68093497812367\n",
      "total training set log likelihood: -179.68093497811813\n",
      "total training set log likelihood: -179.68093497811824\n",
      "maximum likelihood learning rate: 0.17285662667195398\n",
      "maximum likelihood decay rate: 0.3600586415641878\n",
      "maximum likelihood beta on value: 7.919995882218854\n",
      "test set log likelihood: -17.933622456131808\n",
      "test set likelihood per trial: [0.40792126]\n",
      "predicting game: 5\n",
      "total training set log likelihood: -223.61013997055898\n",
      "total training set log likelihood: -223.61014217621295\n",
      "total training set log likelihood: -223.61013977650282\n",
      "total training set log likelihood: -223.61013996647546\n",
      "total training set log likelihood: -346.060538279703\n",
      "total training set log likelihood: -346.0605149534266\n",
      "total training set log likelihood: -346.060538279698\n",
      "total training set log likelihood: -346.06053827969765\n",
      "total training set log likelihood: -208.86860209071057\n",
      "total training set log likelihood: -208.8686018222822\n",
      "total training set log likelihood: -208.86860227099825\n",
      "total training set log likelihood: -208.8686019925027\n",
      "total training set log likelihood: -208.23669807593973\n",
      "total training set log likelihood: -208.23669809347498\n",
      "total training set log likelihood: -208.23669822818837\n",
      "total training set log likelihood: -208.23669798372165\n",
      "total training set log likelihood: -207.83395765260377\n",
      "total training set log likelihood: -207.83395780991228\n",
      "total training set log likelihood: -207.83395777545277\n",
      "total training set log likelihood: -207.83395756279813\n",
      "total training set log likelihood: -207.02489939170835\n",
      "total training set log likelihood: -207.0248996869808\n",
      "total training set log likelihood: -207.0248994435027\n",
      "total training set log likelihood: -207.02489930322545\n",
      "total training set log likelihood: -205.9530294669016\n",
      "total training set log likelihood: -205.95302971139765\n",
      "total training set log likelihood: -205.9530294401409\n",
      "total training set log likelihood: -205.95302937662865\n",
      "total training set log likelihood: -203.5292724213461\n",
      "total training set log likelihood: -203.52927249004205\n",
      "total training set log likelihood: -203.52927232969455\n",
      "total training set log likelihood: -203.5292723372354\n",
      "total training set log likelihood: -199.0346276778864\n",
      "total training set log likelihood: -199.0346270561992\n",
      "total training set log likelihood: -199.0346276027492\n",
      "total training set log likelihood: -199.03462761081383\n",
      "total training set log likelihood: -196.0875304823176\n",
      "total training set log likelihood: -196.08752985591582\n",
      "total training set log likelihood: -196.0875304502809\n",
      "total training set log likelihood: -196.08753043427458\n",
      "total training set log likelihood: -195.9709000998122\n",
      "total training set log likelihood: -195.9709013043418\n",
      "total training set log likelihood: -195.97089967704636\n",
      "total training set log likelihood: -195.9709001122717\n",
      "total training set log likelihood: -193.8694653592422\n",
      "total training set log likelihood: -193.86946561437531\n",
      "total training set log likelihood: -193.86946517596\n",
      "total training set log likelihood: -193.86946534326032\n",
      "total training set log likelihood: -192.35728718135547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training set log likelihood: -192.35728725816037\n",
      "total training set log likelihood: -192.35728721813808\n",
      "total training set log likelihood: -192.3572871768696\n",
      "total training set log likelihood: -192.1552636054931\n",
      "total training set log likelihood: -192.15526360226357\n",
      "total training set log likelihood: -192.15526362447972\n",
      "total training set log likelihood: -192.15526360294237\n",
      "total training set log likelihood: -192.1129155490034\n",
      "total training set log likelihood: -192.1129155392975\n",
      "total training set log likelihood: -192.11291554914806\n",
      "total training set log likelihood: -192.11291554850987\n",
      "total training set log likelihood: -192.11229986024165\n",
      "total training set log likelihood: -192.11229985919417\n",
      "total training set log likelihood: -192.11229986005605\n",
      "total training set log likelihood: -192.11229986018543\n",
      "total training set log likelihood: -192.11229027945532\n",
      "total training set log likelihood: -192.11229027948994\n",
      "total training set log likelihood: -192.1122902794401\n",
      "total training set log likelihood: -192.11229027945507\n",
      "total training set log likelihood: -192.11229027130634\n",
      "total training set log likelihood: -192.11229027131282\n",
      "total training set log likelihood: -192.1122902713049\n",
      "total training set log likelihood: -192.1122902713064\n",
      "maximum likelihood learning rate: 0.17146476072779449\n",
      "maximum likelihood decay rate: 0.4026379510972065\n",
      "maximum likelihood beta on value: 7.781979760205922\n",
      "test set log likelihood: -5.3523829539910714\n",
      "test set likelihood per trial: [0.76519915]\n",
      "predicting game: 6\n",
      "total training set log likelihood: -215.72686834787788\n",
      "total training set log likelihood: -215.72687040355095\n",
      "total training set log likelihood: -215.72686817343123\n",
      "total training set log likelihood: -215.7268683330698\n",
      "total training set log likelihood: -346.05978454584545\n",
      "total training set log likelihood: -346.0597536823553\n",
      "total training set log likelihood: -346.0597845458381\n",
      "total training set log likelihood: -346.05978454583976\n",
      "total training set log likelihood: -199.29108436784702\n",
      "total training set log likelihood: -199.29108414647067\n",
      "total training set log likelihood: -199.29108458772632\n",
      "total training set log likelihood: -199.29108429045226\n",
      "total training set log likelihood: -198.83246519687694\n",
      "total training set log likelihood: -198.83246512286323\n",
      "total training set log likelihood: -198.83246540010668\n",
      "total training set log likelihood: -198.8324651218814\n",
      "total training set log likelihood: -197.42283283458474\n",
      "total training set log likelihood: -197.4228330835817\n",
      "total training set log likelihood: -197.4228329756071\n",
      "total training set log likelihood: -197.42283276739505\n",
      "total training set log likelihood: -195.41735415940917\n",
      "total training set log likelihood: -195.41735468995103\n",
      "total training set log likelihood: -195.417354193852\n",
      "total training set log likelihood: -195.41735410414745\n",
      "total training set log likelihood: -191.98810533225569\n",
      "total training set log likelihood: -191.9881059546086\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-7d14e357477c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m## Train model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_frl_choice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_cond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbehav_training_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L-BFGS-B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'maxfun'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'maxiter'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_game\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbnds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0m\u001b[1;32m    156\u001b[0m                                            **finite_diff_options)\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0m\u001b[1;32m    487\u001b[0m                                      use_one_sided, method)\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3-point'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/NYU/Research/LDM/ldm-analysis/rl-modeling/FeatureRL.py\u001b[0m in \u001b[0;36mtrain_frl_choice\u001b[0;34m(training_params, behav_training_data)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m## Subselect game trials and format data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbehav_training_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbehav_training_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Game'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtraining_games_idxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mextracted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbehav_training_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;31m## Run model to obtain likelihood.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/NYU/Research/LDM/ldm-analysis/rl-modeling/Data.py\u001b[0m in \u001b[0;36mextract_vars\u001b[0;34m(behav_data, trials)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m## Get observations for this game (available stimuli, choices, outcomes, center dimension and feature).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mstimuli_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbehav_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbehav_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stim11'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Stim12'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Stim13'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mstimuli_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbehav_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbehav_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stim21'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Stim22'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Stim23'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mstimuli_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbehav_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbehav_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stim31'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Stim32'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Stim33'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mchoices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbehav_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbehav_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Chosen1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chosen2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Chosen3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2912\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m         \"\"\"\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3350\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3351\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1438\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_convert_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexers.py\u001b[0m in \u001b[0;36mmaybe_convert_indices\u001b[0;34m(indices, n)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"indices are out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "## Set number of iterations.\n",
    "n_iter = 5\n",
    "\n",
    "## Set bounds.\n",
    "bnds = [(1e-6,1), (1e-6,1), (1e-6,500)]\n",
    "\n",
    "## Initialize output arrays.\n",
    "results = np.zeros((n_iter,data.n_games,len(bnds)+1))\n",
    "initial_conditions = np.zeros((n_iter,len(bnds)))\n",
    "\n",
    "## Run optimization with different initial conditions.\n",
    "for i in np.arange(n_iter): \n",
    "    \n",
    "    print('iteration #', i+1)\n",
    "    \n",
    "    ## Set initial conditions.\n",
    "    init_cond = [np.random.uniform(0, 1), np.random.uniform(0, 1), np.random.uniform(2, 5)]\n",
    "    initial_conditions[i,:] = init_cond\n",
    "    print('initial conditions:', init_cond)\n",
    "        \n",
    "    for g in np.arange(data.n_games):\n",
    "    \n",
    "        ## Set current test game. \n",
    "        test_game = g+1\n",
    "        print('predicting game:', test_game)\n",
    "\n",
    "        ## Split behavior into training and test data.\n",
    "        behav_training_data, behav_test_data = data.split_data(test_game)\n",
    "\n",
    "        ## Train model.\n",
    "        res = minimize(train_frl_choice, init_cond, args=(behav_training_data), method='L-BFGS-B', bounds=bnds, options={'maxfun': 150, 'maxiter': 100})\n",
    "        results[i,test_game-1,0:len(bnds)] = res.x\n",
    "\n",
    "        ## Evaluate model on test set.\n",
    "        test_trials = behav_test_data.Trial.unique()        \n",
    "        extracted_data = extract_vars(behav_test_data, test_trials)\n",
    "\n",
    "        ## Set parameters.\n",
    "        # Default values set to 0.\n",
    "        test_params = {'learning_rate': res.x[0],\n",
    "                    'decay_rate': res.x[1],\n",
    "                    'softmax_temperature': res.x[2],\n",
    "                    'w_init': 0,\n",
    "                    'decay_target': 0,\n",
    "                    'precision': 0}\n",
    "        del res\n",
    "\n",
    "        ## Instantiate and run MLE agent.\n",
    "        frl_mle = FRL(world, test_params)\n",
    "        W, test_lik = frl_mle.choice_likelihood(world, extracted_data)\n",
    "        results[i,test_game-1,-1] = test_lik\n",
    "\n",
    "        n_trials = np.shape(extracted_data['outcomes'])\n",
    "        \n",
    "        print('maximum likelihood learning rate:', test_params['learning_rate'])\n",
    "        print('maximum likelihood decay rate:', test_params['decay_rate'])\n",
    "        print('maximum likelihood beta on value:', test_params['softmax_temperature'])\n",
    "        print('test set log likelihood:', test_lik)\n",
    "        \n",
    "        print('test set likelihood per trial:', np.exp(test_lik/n_trials))\n",
    "        \n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed time: ' + str((np.round(elapsed_time,decimals=3))) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize and save fit object.\n",
    "fit = Fit(subj_id, n_iter, initial_conditions, results, elapsed_time)\n",
    "pickle.dump(fit, fit_file)\n",
    "fit_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test that fit was saved correctly. \n",
    "new_fit_file = open(fit_path,'rb')\n",
    "loaded_fit = pickle.load(new_fit_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_fit.elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
