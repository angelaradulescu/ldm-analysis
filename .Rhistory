car::Anova(m1, type = '3')
m2 <- lmer(data = model_data, formula = Entropy ~ scaled_age*WithinGameTrial*Game*Learned + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
View(data)
model_data <- data %>%
select(Subj, Entropy, Age, Adult, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj))
model_data[model_data$LearnedGame == TRUE,]
View(model_data)
model_data[model_data$LearnedGame == 'True',]
learning_trials <- model_data[model_data$LearnedGame == 'True',]
learning_trials$AlignedTrial = learning_trials$WithinGameTrial - learning_trials$PoL
View(learning_trials)
model_data$AlignedTrial = model_data$WithinGameTrial - model_data$PoL
View(model_data)
m1 <- lmer(data = model_data, formula = Entropy ~ scaled_age*AlignedTrial + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
m2 <- lmer(data = model_data, formula = Entropy ~ scaled_age*AlignedTrial*Game*LearnedGame + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
m3 <- lmer(data = model_data, formula = Entropy ~ scaled_age*WithinGameTrial*Game*LearnedGame + ((WithinGameTrial * (Game+LearnedGame))|subject_id))
summary(m3)
## Omnibus test.
car::Anova(m3, type = '3')
m3 <- lmer(data = model_data, formula = Entropy ~ scaled_age*AlignedTrial*Game*LearnedGame + ((AlignedTrial * (Game+LearnedGame))|subject_id))
summary(m3)
## Omnibus test.
car::Anova(m3, type = '3')
library(lattice)
library(lme4)
library(lmerTest)
library(psycho)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/Feedback_Processed_CombinedBehavioralEyetrackingData.csv')
# Clean data if needed
# clean_feedback_data <- feedback_data %>%
#   clean_names() %>%
#   select('subj', 'iq', 'within_game_trial', 'trial', 'game', 'entropy', 'age_group', 'po_l', 'rt', 'learned_feat', 'correct') %>%
#   rename('pol' = 'po_l')
#
# clean_feedback_data$age_group <- as.factor(clean_feedback_data$age_group)
##### Helper function for rescaling data
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
## Select relevant data and rescale ##
model_data <- data %>%
select(Subj, Entropy, Age, Adult, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj))
#######Continunous Age + Game-wise Learned Parameter#######
## Basic Mixed Model ##
## just Age*LearnedGame as fixed effects Subj as random effect. ##
m1 <- lmer(data = model_data, formula = Entropy ~ scaled_age*LearnedGame + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
## More Mixed Model ##
## Age*WithinGameTrial*Game*LearnedGame as fixed effects Subj as random effect. ##
# fit warnings: Some predictor variables are on very different scales: consider rescaling # NB: no longer appearing after rescaling age and iq
m2 <- lmer(data = model_data, formula = Entropy ~ scaled_age*WithinGameTrial*Game*LearnedGame + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
## Even More Mixed Model ##
## Age*WithinGameTrial*Game*LearnedGame as fixed effects that act on Subj as random effect. ##
## Fitting this model resulted in singularity of the model. FMI: enter ?isSingular in console
m3 <- lmer(data = model_data, formula = Entropy ~ scaled_age*WithinGameTrial*Game*LearnedGame + ((WithinGameTrial * (Game+LearnedGame))|subject_id))
summary(m3)
## Omnibus test.
car::Anova(m3, type = '3')
### Mixed Model Playground (trying out different things) ###
m4 <- lmer(data = data, formula = Entropy ~ scaled_age*(WithinGameTrial + Game) + ((WithinGameTrial + Game)|subject_id))
summary(m4)
## Omnibus test.
car::Anova(m4, type = '3')
#######Continunous Age, separated by PoL#######
# make new AlignedTrial value
# learning_trials <- model_data[model_data$LearnedGame == 'True',]
# learning_trials$AlignedTrial = learning_trials$WithinGameTrial - learning_trials$PoL
model_data$AlignedTrial = model_data$WithinGameTrial - model_data$PoL
# split data based on pre and post learning
pre_learning_trials <- model_data[model_data$AlignedTrial < 0,]
post_learning_trials <- model_data[model_data$AlignedTrial > 0,]
pre_m1 <- lmer(data = pre_learning_trials, formula = Entropy ~ scaled_age + (1|subject_id))
summary(pre_m1)
## Omnibus test.
car::Anova(pre_m1, type = '3')
# post learning
post_m1 <- lmer(data = pre_learning_trials, formula = Entropy ~ scaled_age + (1|subject_id))
summary(post_m1)
## Omnibus test.
car::Anova(post_m1, type = '3')
pre_m1 <- lmer(data = pre_learning_trials, formula = Entropy ~ scaled_age + (1|subject_id))
summary(pre_m1)
## Omnibus test.
car::Anova(pre_m1, type = '3')
# post learning
post_m1 <- lmer(data = post_learning_trials, formula = Entropy ~ scaled_age + (1|subject_id))
summary(post_m1)
## Omnibus test.
car::Anova(post_m1, type = '3')
model_data$LearnedYet = model_data$AlignedTrial > 0
View(model_data)
m1 <- lmer(data = model_data, formula = Entropy ~ scaled_age*LearnedYet + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
m2 <- lmer(data = model_data, formula = Entropy ~ scaled_age*AlignedTrial*Game*LearnedYet + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
m2 <- lmer(data = model_data, formula = Entropy ~ scaled_age*WithinGameTrial*Game*LearnedYet + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
m3 <- lmer(data = model_data, formula = Entropy ~ scaled_age*AlignedTrial*Game*LearnedYet + ((AlignedTrial * (Game+LearnedYet))|subject_id))
summary(m3)
## Omnibus test.
car::Anova(m3, type = '3')
m2 <- lmer(data = model_data, formula = Entropy ~ scaled_age*AlignedTrial*Game*LearnedYet + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
m2 <- lmer(data = model_data, formula = Entropy ~ scaled_age*AlignedTrial*Game*LearnedGame + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
View(data)
behav_data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/CleanedProcessedBehavioralData.csv')
View(behav_data)
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, IQ, PoL) %>%
unique()
View(sub_summary)
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, PoL) %>%
unique() %>%
group_by(Subj,Age) %>%
summarize(GamesLearned = sum(LearnedGame))
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, PoL) %>%
unique() %>%
group_by(Subj,Age) %>%
mutate(LearnedGame = bool(LearnedGame)) %>%
summarize(GamesLearned = sum(LearnedGame))
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, PoL) %>%
unique() %>%
group_by(Subj,Age) %>%
mutate(LearnedGame = as.logical(LearnedGame)) %>%
summarize(GamesLearned = sum(LearnedGame))
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, PoL) %>%
unique() %>%
group_by(Subj,Age) %>%
mutate(LearnedGame = as.logical(LearnedGame)) %>%
summarize(GamesLearned = sum(LearnedGame)) %>%
ungroup()
behav_data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/CleanedProcessedBehavioralData.csv')
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, PoL) %>%
unique() %>%
group_by(Subj,Age) %>%
mutate(LearnedGame = as.logical(LearnedGame)) %>%
summarize(GamesLearned = sum(LearnedGame))
sub_summary %<>% mutate(age_scaled = scale_this(Age))
lm(GamesLearned ~ age_scaled, age_iq_data) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
## Linear Regression Model ##
# Load needed libraries
library(tidyverse)
library(glue)
library(magrittr)
library(afex)
library(knitr)
library(kableExtra)
library(broom)
lm(GamesLearned ~ age_scaled, age_iq_data) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
lm(GamesLearned ~ age_scaled, sub_summary) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
## Linear Regression Model ##
# Load needed libraries
library(tidyverse)
library(glue)
library(magrittr)
library(afex)
library(knitr)
library(kableExtra)
library(broom)
# scale function (z-score)
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
# run wasi iq analysis
age_iq_data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/ageIQMap.csv')
age_iq_data %<>%
mutate(age_scaled = scale_this(Age),
iq_scaled = scale_this(IQ))
lm(IQ ~ Age, age_iq_data) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
####################### AgexNumberOfGamesLearned ###############################
behav_data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/CleanedProcessedBehavioralData.csv')
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, PoL) %>%
unique() %>%
group_by(Subj,Age) %>%
mutate(LearnedGame = as.logical(LearnedGame)) %>%
summarize(GamesLearned = sum(LearnedGame))
sub_summary %<>% mutate(age_scaled = scale_this(Age))
lm(GamesLearned ~ age_scaled, sub_summary) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
lm(GamesLearned ~ Age, sub_summary) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
scale_this(Age)
sub_summary %<>% mutate(age_scaled = scale_this(Age))
## Linear Regression Model ##
# Load needed libraries
library(tidyverse)
library(glue)
library(magrittr)
library(afex)
library(knitr)
library(kableExtra)
library(broom)
# scale function (z-score)
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
scale_this(sub_summary$Age)
behav_data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/CleanedProcessedBehavioralData.csv')
sub_summary <- behav_data %>%
select(Subj, Age, LearnedGame, PoL) %>%
unique() %>%
group_by(Subj,Age) %>%
mutate(LearnedGame = as.logical(LearnedGame)) %>%
summarize(GamesLearned = sum(LearnedGame))
scale_this(sub_summary$Age)
sub_summary$age_scaled <- scale_this(sub_summary$Age)
lm(GamesLearned ~ age_scaled, sub_summary) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
lm(GamesLearned ~ Age, sub_summary) %>%
tidy() %>%
kable()%>%
kable_classic(full_width = F, html_font = "Arial") %>%
kable_styling("striped", position = "float_left")
m1 <- lmer(data = model_data, formula = Entropy ~ scaled_age*LearnedYet + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/Feedback_Processed_CombinedBehavioralEyetrackingData.csv')
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
##################### Select relevant data and rescale #####################
model_data <- data %>%
select(Subj, Entropy, Age, Adult, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj))
m1 <- lmer(data = model_data, formula = Entropy ~ scaled_age*LearnedYet + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
model_data$AlignedTrial = model_data$WithinGameTrial - model_data$PoL
model_data$LearnedYet = model_data$AlignedTrial > 0
## Basic Mixed Model ##
## just Age as fixed effect and Subj as random effect. ##
m1 <- lmer(data = model_data, formula = Entropy ~ scaled_age*LearnedYet + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
m1 <- lmer(data = model_data, formula = Entropy ~ Age*LearnedYet + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
m1 <- lmer(data = model_data, formula = Entropy ~ scaled_age*LearnedYet + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
## Linear Regression Model ##
# Load needed libraries
library(tidyverse)
library(glue)
library(magrittr)
library(afex)
library(knitr)
library(kableExtra)
library(broom)
data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/Feedback_Processed_CombinedBehavioralEyetrackingData.csv')
model_data <- data %>%
select(Subj, Entropy, Age, Adult, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj))
model_data$AlignedTrial <- model_data$WithinGameTrial - model_data$PoL
model_data$LearnedYet <- model_data$AlignedTrial > 0
adult_data <- model_data[model_data$Adult == 'True',]
adole_data <- model_data[model_data$Adult == 'False',]
# scale function (z-score)
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
model_data <- data %>%
select(Subj, Entropy, Age, Adult, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj))
model_data$AlignedTrial <- model_data$WithinGameTrial - model_data$PoL
model_data$LearnedYet <- model_data$AlignedTrial > 0
adult_data <- model_data[model_data$Adult == 'True',]
adole_data <- model_data[model_data$Adult == 'False',]
data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/Feedback_Processed_CombinedBehavioralEyetrackingData.csv')
model_data <- data %>%
select(Subj, Entropy, Age, Adult, AgeGroup, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj))
model_data$AlignedTrial <- model_data$WithinGameTrial - model_data$PoL
model_data$LearnedYet <- model_data$AlignedTrial > 0
adult_data <- model_data[model_data$Adult == 'True',]
adole_data <- model_data[model_data$Adult == 'False',]
fit = lm(Entropy~WithinGameTrial+AgeGroup,data=model_data)
summary(fit)
equation1=function(x){coef(fit)[2]*x+coef(fit)[1]}
equation2=function(x){coef(fit)[2]*x+coef(fit)[1]+coef(fit)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup))+geom_point()+
stat_function(fun=equation1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2,geom="line",color=scales::hue_pal()(2)[2])
fit1 = lm(Entropy~WithinGameTrial+LearnedGame,data=model_data)
summary(fit1)
equation1_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]}
equation2_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]+coef(fit1)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=LearnedGame))+geom_point()+
stat_function(fun=equation1_1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2_1,geom="line",color=scales::hue_pal()(2)[2])
fit = lm(Entropy~WithinGameTrial+AgeGroup,data=model_data)
summary(fit)
equation1=function(x){coef(fit)[2]*x+coef(fit)[1]}
equation2=function(x){coef(fit)[2]*x+coef(fit)[1]+coef(fit)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup))+geom_point()+
stat_function(fun=equation1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2,geom="line",color=scales::hue_pal()(2)[2])
fit1 = lm(Entropy~WithinGameTrial+LearnedGame,data=model_data)
summary(fit1)
equation1_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]}
equation2_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]+coef(fit1)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=LearnedGame))+geom_point()+
stat_function(fun=equation1_1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2_1,geom="line",color=scales::hue_pal()(2)[2])
fit = lm(Entropy~WithinGameTrial+AgeGroup,data=model_data)
summary(fit)
equation1=function(x){coef(fit)[2]*x+coef(fit)[1]}
equation2=function(x){coef(fit)[2]*x+coef(fit)[1]+coef(fit)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup))+geom_point()+
stat_function(fun=equation1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit1,se=TRUE,interactive=TRUE)
require(ggiraph)
require(ggiraphExtra)
require(plyr)
ggPredict(fit1,se=TRUE,interactive=TRUE)
require(ggiraph)
require(ggiraphExtra)
require(plyr)
ggPredict(fit1,se=TRUE,interactive=TRUE)
fit2 = lm(Entropy~WithinGameTrial+AgeGroup+LearnedGame,data=model_data)
summary(fit2)
ggPredict(fit2,se=TRUE,interactive=TRUE)
ggPredict(fit1,se=TRUE,interactive=TRUE)
ggPredict(fit2,se=TRUE,interactive=TRUE)
library(lattice)
library(lme4)
library(lmerTest)
library(psycho)
library(magrittr) # needs to be run every time you start R and want to use %>%
library(dplyr)    # alternatively, this also loads %>%
##################### Import Data #####################
data <- read.csv('https://raw.githubusercontent.com/angelaradulescu/ldm-analysis/main/ProcessedData/Feedback_Processed_CombinedBehavioralEyetrackingData.csv')
# Clean data if needed
# clean_feedback_data <- feedback_data %>%
#   clean_names() %>%
#   select('subj', 'iq', 'within_game_trial', 'trial', 'game', 'entropy', 'age_group', 'po_l', 'rt', 'learned_feat', 'correct') %>%
#   rename('pol' = 'po_l')
#
# clean_feedback_data$age_group <- as.factor(clean_feedback_data$age_group)
##################### Helper function for rescaling data #####################
scale_this <- function(x){
(x - mean(x, na.rm=TRUE)) / sd(x, na.rm=TRUE)
}
##################### Select relevant data and rescale #####################
model_data <- data %>%
select(Subj, Entropy, Age, AgeGroup, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj))
model_data$AlignedTrial = model_data$WithinGameTrial - model_data$PoL
model_data$LearnedYet = model_data$AlignedTrial > 0
m1 <- lmer(data = model_data, formula = Entropy ~ AgeGroup*LearnedGame + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
m1 <- lmer(data = model_data, formula = Entropy ~ AgeGroup + LearnedGame + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
m1 <- lmer(data = model_data, formula = Entropy ~ AgeGroup*LearnedGame + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
model_data <- data %>%
select(Subj, Entropy, Age, AgeGroup, WithinGameTrial, Game, LearnedGame, Learned, IQ, PoL) %>%
mutate(scaled_age = scale_this(Age),
scaled_iq = scale_this(IQ),
subject_id = as.factor(Subj),
age_group = as.factor(AgeGroup))
model_data$AlignedTrial = model_data$WithinGameTrial - model_data$PoL
model_data$LearnedYet = model_data$AlignedTrial > 0
m1 <- lmer(data = model_data, formula = Entropy ~ age_group*LearnedGame + (1|subject_id))
summary(m1)
## Omnibus test.
car::Anova(m1, type = '3')
m2 <- lmer(data = model_data, formula = Entropy ~ age_group*WithinGameTrial*Game*LearnedGame + (1|subject_id))
summary(m2)
## Omnibus test.
car::Anova(m2, type = '3')
fit1 = lm(Entropy~WithinGameTrial*LearnedGame,data=model_data)
summary(fit1)
equation1_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]}
equation2_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]+coef(fit1)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=LearnedGame))+geom_point()+
stat_function(fun=equation1_1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2_1,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit1,se=TRUE,interactive=TRUE)
fit = lm(Entropy~WithinGameTrial*AgeGroup,data=model_data)
summary(fit)
equation1=function(x){coef(fit)[2]*x+coef(fit)[1]}
equation2=function(x){coef(fit)[2]*x+coef(fit)[1]+coef(fit)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup))+geom_point()+
stat_function(fun=equation1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit,se=TRUE,interactive=TRUE)
fit = lm(Entropy~WithinGameTrial+AgeGroup,data=model_data)
summary(fit)
equation1=function(x){coef(fit)[2]*x+coef(fit)[1]}
equation2=function(x){coef(fit)[2]*x+coef(fit)[1]+coef(fit)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup))+geom_point()+
stat_function(fun=equation1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit,se=TRUE,interactive=TRUE)
fit1 = lm(Entropy~WithinGameTrial*LearnedGame,data=model_data)
summary(fit1)
equation1_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]}
equation2_1=function(x){coef(fit1)[2]*x+coef(fit1)[1]+coef(fit1)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=LearnedGame))+geom_point()+
stat_function(fun=equation1_1,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2_1,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit1,se=TRUE,interactive=TRUE)
fit2 = lm(Entropy~WithinGameTrial*LearnedGame+AgeGroup,data=model_data)
summary(fit2)
equation1_2=function(x){coef(fit2)[2]*x+coef(fit2)[1]}
equation2_2=function(x){coef(fit2)[2]*x+coef(fit2)[1]+coef(fit2)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup,color=LearnedGame))+geom_point()+
stat_function(fun=equation1_2,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2_2,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit2,se=TRUE,interactive=TRUE)
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup,linetype=LearnedGame))+geom_point()+
stat_function(fun=equation1_2,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2_2,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit2,se=TRUE,interactive=TRUE)
fit2 = lm(Entropy~WithinGameTrial*LearnedGame+AgeGroup,data=model_data)
summary(fit2)
equation1_2=function(x){coef(fit2)[2]*x+coef(fit2)[1]}
equation2_2=function(x){coef(fit2)[2]*x+coef(fit2)[1]+coef(fit2)[3]}
ggplot(model_data,aes(y=Entropy,x=WithinGameTrial,color=AgeGroup,linetype=LearnedGame))+geom_point()+
stat_function(fun=equation1_2,geom="line",color=scales::hue_pal()(2)[1])+
stat_function(fun=equation2_2,geom="line",color=scales::hue_pal()(2)[2])
ggPredict(fit2,se=TRUE,interactive=TRUE)
